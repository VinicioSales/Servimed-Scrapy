# ğŸ•·ï¸ Servimed Scraper - Desafio TÃ©cnico CotefÃ¡cil

## ğŸ“‹ DescriÃ§Ã£o

AplicaÃ§Ã£o completa para web scraping do fornecedor Servimed com processamento assÃ­ncrono via filas e integraÃ§Ã£o com API de callback, desenvolvida conforme especificaÃ§Ã£o do Desafio TÃ©cnico da CotefÃ¡cil.

## ğŸ¯ NÃ­veis Implementados

### âœ… NÃ­vel 1 - BÃ¡sico (100% Completo)
- âœ… Login no site Servimed
- âœ… ExtraÃ§Ã£o de produtos (GTIN, CÃ³digo, DescriÃ§Ã£o, PreÃ§o, Estoque)
- âœ… Uso exclusivo do Scrapy
- âœ… Armazenamento em JSON

### âœ… NÃ­vel 2 - IntermediÃ¡rio (100% Completo)
- âœ… Sistema de filas assÃ­ncronas (Celery)
- âœ… Processamento independente de tarefas
- âœ… IntegraÃ§Ã£o com API callback
- âœ… AutenticaÃ§Ã£o OAuth2
- âœ… Endpoint `POST /produto`

### âœ… NÃ­vel 3 - AvanÃ§ado (100% Completo)
- âœ… Processamento de pedidos
- âœ… CÃ³digo de confirmaÃ§Ã£o
- âœ… Endpoint `PATCH /pedido/:id`
- âœ… Testes automatizados
- âœ… API completa

## ğŸ—ï¸ Arquitetura

```
ğŸ“¦ Servimed Scraper
â”œâ”€â”€ ğŸ•·ï¸ Spider Scrapy (Login + Scraping)
â”œâ”€â”€ ğŸ”Œ Cliente API (CotefÃ¡cil Integration)
â”œâ”€â”€ âš¡ Sistema Celery (Async Queues)
â”œâ”€â”€ ğŸŒ API FastAPI (REST Interface)
â”œâ”€â”€ ğŸ§ª Testes (pytest)
â””â”€â”€ ğŸ“Š Monitoramento (Flower)
```

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <repository-url>
cd Scrapy-Servimed
```

### 2. Crie ambiente virtual
```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 3. Instale dependÃªncias
```bash
pip install -r requirements.txt
```

### 4. Configure variÃ¡veis de ambiente
```bash
cp .env.example .env
# Edite o arquivo .env com suas credenciais
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo `.env`
```env
# Credenciais do Servimed
SERVIMED_USERNAME=juliano@farmaprevonline.com.br
SERVIMED_PASSWORD=a007299A
SERVIMED_CLIENT_ID=267511

# Credenciais da API CotefÃ¡cil
COTEFACIL_USERNAME=juliano@farmaprevonline.com.br
COTEFACIL_PASSWORD=a007299A
COTEFACIL_CLIENT_ID=267511
COTEFACIL_CLIENT_SECRET=05272420000221

# URLs
SERVIMED_BASE_URL=https://pedidoeletronico.servimed.com.br
SERVIMED_API_URL=https://peapi.servimed.com.br
COTEFACIL_BASE_URL=https://desafio.cotefacil.net

# Redis (opcional - usa memÃ³ria por padrÃ£o)
REDIS_URL=redis://localhost:6379/0
```

## ğŸ”§ ExecuÃ§Ã£o

### NÃ­vel 1 - Scraping BÃ¡sico
```bash
cd servimed_scraper
scrapy crawl servimed -o produtos.json -L INFO
```

### NÃ­vel 2 & 3 - Sistema Completo

#### 1. Iniciar API
```bash
cd servimed_scraper
python challenge_api.py
```

#### 2. Enfileirar tarefa de scraping (NÃ­vel 2)
```bash
curl -X POST "http://localhost:8000/nivel2/scrape" \
  -H "Content-Type: application/json" \
  -d '{
    "usuario": "fornecedor_user",
    "senha": "fornecedor_pass",
    "callback_url": "https://desafio.cotefacil.net"
  }'
```

#### 3. Enfileirar tarefa de pedido (NÃ­vel 3)
```bash
curl -X POST "http://localhost:8000/nivel3/order" \
  -H "Content-Type: application/json" \
  -d '{
    "usuario": "fornecedor_user",
    "senha": "fornecedor_pass",
    "id_pedido": "1234",
    "produtos": [
      {
        "gtin": "1234567890123",
        "codigo": "A123",
        "quantidade": 1
      }
    ],
    "callback_url": "https://desafio.cotefacil.net"
  }'
```

#### 4. Verificar status da tarefa
```bash
curl "http://localhost:8000/task/{task_id}"
```

## ğŸ§ª Testes

### Executar todos os testes
```bash
pytest tests/ -v
```

### Teste especÃ­fico
```bash
pytest tests/test_cotefacil_client.py -v
```

### Teste com coverage
```bash
pip install pytest-cov
pytest tests/ --cov=servimed_scraper --cov-report=html
```

## ğŸ“¡ API Endpoints

### Principais Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/` | InformaÃ§Ãµes da API |
| `POST` | `/nivel2/scrape` | Scraping de produtos (NÃ­vel 2) |
| `POST` | `/nivel3/order` | Processamento de pedido (NÃ­vel 3) |
| `GET` | `/task/{id}` | Status da tarefa |
| `GET` | `/health` | Health check |
| `POST` | `/setup/user` | Configurar usuÃ¡rio na API |

### DocumentaÃ§Ã£o Interativa
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ” Monitoramento

### Flower (Monitor Celery)
```bash
cd servimed_scraper
celery -A celery_app flower
# Acesse: http://localhost:5555
```

### Logs
- API: SaÃ­da do terminal
- Celery: Logs do worker
- Scrapy: Log level configurÃ¡vel

## ğŸ›ï¸ Estrutura do Projeto

```
Scrapy-Servimed/
â”œâ”€â”€ servimed_scraper/
â”‚   â”œâ”€â”€ servimed_scraper/
â”‚   â”‚   â”œâ”€â”€ clients/
â”‚   â”‚   â”‚   â””â”€â”€ cotefacil_client.py
â”‚   â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”‚   â””â”€â”€ servimed_spider.py
â”‚   â”‚   â””â”€â”€ tasks/
â”‚   â”‚       â”œâ”€â”€ challenge_tasks.py
â”‚   â”‚       â””â”€â”€ scraping_tasks.py
â”‚   â”œâ”€â”€ celery_app.py
â”‚   â”œâ”€â”€ challenge_api.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_cotefacil_client.py
â”‚   â””â”€â”€ test_challenge_tasks.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ” SeguranÃ§a

- âœ… VariÃ¡veis de ambiente para credenciais
- âœ… Arquivo `.env` no `.gitignore`
- âœ… Timeout em requisiÃ§Ãµes
- âœ… Retry automÃ¡tico com backoff
- âœ… Headers de seguranÃ§a

## ğŸš€ Deploy

### Docker (Opcional)
```dockerfile
FROM python:3.10
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "servimed_scraper/challenge_api.py"]
```

### ProduÃ§Ã£o
1. Configure Redis/RabbitMQ
2. Use supervisor/systemd para workers
3. Configure nginx para API
4. Monitore com Flower

## ğŸ› ï¸ Tecnologias

- **Python 3.10+**
- **Scrapy 2.13+** - Web scraping
- **Celery** - Filas assÃ­ncronas
- **FastAPI** - API REST
- **Redis** - Message broker
- **pytest** - Testes
- **Flower** - Monitoramento

## ğŸ“Š Conformidade com Requisitos

### âœ… Requisitos Funcionais
- [x] Login autenticado no Servimed
- [x] ExtraÃ§Ã£o de dados de produtos
- [x] Sistema de filas assÃ­ncronas
- [x] IntegraÃ§Ã£o com API callback
- [x] Processamento de pedidos
- [x] CÃ³digo de confirmaÃ§Ã£o

### âœ… Requisitos TÃ©cnicos
- [x] Uso exclusivo do Scrapy
- [x] CÃ³digo modular e limpo
- [x] Tratamento de erros
- [x] Logs detalhados
- [x] Testes automatizados
- [x] DocumentaÃ§Ã£o completa

### âœ… Endpoints Conforme EspecificaÃ§Ã£o
- [x] `POST /produto` - Envio de produtos
- [x] `PATCH /pedido/:id` - ConfirmaÃ§Ã£o de pedido
- [x] AutenticaÃ§Ã£o OAuth2
- [x] Estrutura de dados exata

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique os logs
2. Execute os testes
3. Consulte a documentaÃ§Ã£o da API
4. Use o health check

## ğŸ”„ Versionamento

- **v1.0.0** - ImplementaÃ§Ã£o completa dos 3 nÃ­veis
- Todos os requisitos do desafio atendidos
- Testes automatizados incluÃ­dos
