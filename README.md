# ğŸ“– SERVIMED SCRAPER - DOCUMENTAÃ‡ÃƒO COMPLETA

## ğŸ—ï¸ VISÃƒO GERAL

O **Servimed Scraper** Ã© um sistema completo de web scraping e processamento de pedidos desenvolvido em Python para o **Desafio CotefFÃ¡cil**. O projeto implementa uma arquitetura em 3 nÃ­veis de complexidade, sempre utilizando o framework **Scrapy** como base.

### ğŸ¯ OBJETIVOS
- âœ… Extrair dados de produtos farmacÃªuticos do site Servimed
- âœ… Processar pedidos no portal Servimed
- âœ… Integrar com API do desafio CotefFÃ¡cil
- âœ… Implementar sistema de filas para processamento assÃ­ncrono
- âœ… Fornecer cÃ³digos de rastreamento Ãºnicos para pedidos

## ğŸš€ INSTALAÃ‡ÃƒO E CONFIGURAÃ‡ÃƒO

### ğŸ“‹ PrÃ©-requisitos
- **Python 3.10+**
- **Windows 10/11** (ou sistemas compatÃ­veis)
- **ConexÃ£o com internet** (para instalaÃ§Ã£o de dependÃªncias)

### âš¡ ConfiguraÃ§Ã£o RÃ¡pida

1. **Clone ou baixe o projeto:**
   ```bash
   git clone <repositorio>
   cd servimed-scrapy
   ```

2. **Execute a configuraÃ§Ã£o automÃ¡tica:**
   ```bat
   setup.bat
   ```

   Este script irÃ¡:
   - âœ… Criar ambiente virtual Python
   - âœ… Instalar todas as dependÃªncias
   - âœ… Configurar Redis para processamento de filas
   - âœ… Preparar arquivo de configuraÃ§Ã£o (.env)

3. **Configurar variÃ¡veis de ambiente:**
   - Edite o arquivo `.env` com suas credenciais
   - Configure especialmente `COTEFACIL_EMAIL` e `COTEFACIL_PASSWORD`

## ğŸ¯ USO DO SISTEMA

### NÃ­vel 1 - Scrapy Simples
```bash
python main.py nivel1
```
Executa scraping bÃ¡sico usando apenas Scrapy, sem sistema de filas.

### NÃ­vel 2 - Scrapy + Celery
```bash
# Terminal 1 - Iniciar Worker (da raiz do projeto):
start_worker.bat
# ou manualmente:
python -m celery -A src.nivel2.celery_app worker --loglevel=info

# Terminal 2 - Executar programa:
python main.py nivel2
```
Adiciona sistema de filas assÃ­ncronas com Celery + Redis.

### NÃ­vel 3 - Sistema Completo
```bash
# Terminal 1 - Iniciar Worker (da raiz do projeto):
start_worker.bat
# ou manualmente:
python -m celery -A src.nivel2.celery_app worker --loglevel=info

# Terminal 2 - Executar programa:
python main.py nivel3
```
Sistema completo com processamento de pedidos e integraÃ§Ã£o com API CotefFÃ¡cil.

## ğŸ§ª TESTES

### Executar todos os testes:
```bash
python run_tests.py
```

### Executar testes especÃ­ficos:
```bash
# Testes de configuraÃ§Ã£o
python -m pytest tests/test_config.py -v

# Testes de funcionalidade bÃ¡sica
python -m pytest tests/test_basic_functionality.py -v

# Testes do main simplificado
python -m pytest tests/test_main_simple.py -v

# Testes do wrapper Scrapy
python -m pytest tests/test_scrapy_wrapper_simple.py -v

# Testes do nÃ­vel 3
python -m pytest tests/test_nivel3_simple.py -v
```

## ğŸ“ SCRIPTS AUXILIARES

### `setup.bat`
Script de configuraÃ§Ã£o automÃ¡tica que prepara todo o ambiente de desenvolvimento.

### `start_worker.bat`
Script para iniciar o worker Celery de forma simplificada (necessÃ¡rio para nÃ­veis 2 e 3).

### `scripts/redis_start.bat`
Script manual para iniciar Redis se necessÃ¡rio.

## âš ï¸ SOLUÃ‡ÃƒO DE PROBLEMAS

### âŒ **Problema**: ModuleNotFoundError ao executar worker
```
ModuleNotFoundError: No module named 'src'
```
**âœ… SoluÃ§Ã£o**:
```bash
# 1. SEMPRE execute start_worker.bat da RAIZ do projeto
cd /caminho/para/servimed-scrapy
start_worker.bat

# 2. NÃƒO execute de subpastas como scripts/
# âŒ Errado: scripts\start_worker.bat  
# âœ… Correto: start_worker.bat (da raiz)

# 3. Verificar estrutura:
dir main.py src venv  # Devem existir todos
```

### Erro: "Redis nÃ£o conecta"
```
Error 10061 connecting to localhost:6379
```
**SoluÃ§Ã£o:**
1. Execute `start_worker.bat` que inicia Redis automaticamente
2. Ou execute manualmente: `scripts\redis_start.bat`
3. Verifique se `tools/redis-portable/redis-server.exe` existe

### Erro: "ModuleNotFoundError"
**SoluÃ§Ã£o:**
1. Ative o ambiente virtual: `venv\Scripts\activate`
2. Instale dependÃªncias: `pip install -r requirements.txt`
3. Execute da raiz do projeto

### Erro: "Token expirado"
**SoluÃ§Ã£o:**
1. Configure o arquivo `.env` com credenciais vÃ¡lidas
2. Verifique `COTEFACIL_EMAIL` e `COTEFACIL_PASSWORD`

### Celery Worker nÃ£o inicia
**SoluÃ§Ã£o:**
1. Verifique se Redis estÃ¡ rodando
2. Ative o ambiente virtual
3. Execute: `python -m celery -A src.nivel2.celery_app worker --loglevel=info`

## ğŸ”§ DESENVOLVIMENTO

### Estrutura do CÃ³digo

#### `main.py`
Ponto de entrada principal do sistema. Gerencia a execuÃ§Ã£o dos 3 nÃ­veis:
- **NÃ­vel 1**: Scrapy direto
- **NÃ­vel 2**: Scrapy + Celery 
- **NÃ­vel 3**: Sistema completo com API CotefFÃ¡cil

#### `src/scrapy_wrapper.py`
Wrapper unificado que encapsula todas as funcionalidades do Scrapy, permitindo execuÃ§Ã£o via subprocess para evitar conflitos de reactor.

#### `src/pedido_queue_client.py`
Cliente para enfileiramento e monitoramento de pedidos no sistema de filas Celery.

#### Sistema de Filas (`src/nivel2/`)
- **`celery_app.py`**: ConfiguraÃ§Ã£o do Celery
- **`tasks.py`**: Tarefas assÃ­ncronas para processamento
- **`queue_client.py`**: Cliente para interaÃ§Ã£o com filas

#### Sistema de Pedidos (`src/nivel3/`)
- **`tasks.py`**: Processamento completo de pedidos
- **`pedido_client.py`**: Cliente para interaÃ§Ã£o com portal Servimed

#### API CotefFÃ¡cil (`src/api_client/`)
- **`callback_client.py`**: IntegraÃ§Ã£o com API do desafio

### ConfiguraÃ§Ã£o de Ambiente

O arquivo `.env` deve conter:
```bash
# Credenciais CotefFÃ¡cil
COTEFACIL_EMAIL=seu-email@exemplo.com
COTEFACIL_PASSWORD=sua-senha

# URLs da API
COTEFACIL_LOGIN_URL=https://desafio.cotefacil.net/login
COTEFACIL_CHALLENGE_URL=https://desafio.cotefacil.net/challenge

# ConfiguraÃ§Ãµes Redis/Celery
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER=redis://localhost:6379/0

# ConfiguraÃ§Ãµes de log
LOG_LEVEL=INFO
```

## ğŸ“ ESTRUTURA DO PROJETO

```
PROVA/
â”œâ”€â”€ ğŸ“„ main.py                    # Ponto de entrada principal
â”œâ”€â”€ ğŸ“„ setup.bat                  # ConfiguraÃ§Ã£o automÃ¡tica
â”œâ”€â”€ ğŸ“„ start_worker.bat           # Iniciar worker Celery
â”œâ”€â”€ ğŸ“„ run_tests.py               # Executar testes
â”œâ”€â”€ ğŸ“„ requirements.txt           # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ .env.example              # Template de configuraÃ§Ã£o
â”œâ”€â”€ ğŸ“„ README.md                 # Esta documentaÃ§Ã£o
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“ src/                      # CÃ³digo fonte
â”‚   â”œâ”€â”€ ğŸ“„ scrapy_wrapper.py     # Wrapper principal Scrapy
â”‚   â”œâ”€â”€ ğŸ“„ pedido_queue_client.py # Cliente de pedidos
â”‚   â”œâ”€â”€ ğŸ“ nivel2/               # Sistema de filas
â”‚   â”œâ”€â”€ ğŸ“ nivel3/               # Sistema completo
â”‚   â”œâ”€â”€ ğŸ“ api_client/           # IntegraÃ§Ã£o CotefFÃ¡cil
â”‚   â””â”€â”€ ğŸ“ scrapy_servimed/      # Projeto Scrapy
â”‚
â”œâ”€â”€ ğŸ“ tests/                    # Testes automatizados (58 testes)
â”œâ”€â”€ ğŸ“ scripts/                  # Scripts auxiliares
â”œâ”€â”€ ğŸ“ tools/                    # Redis portÃ¡til
â”œâ”€â”€ ğŸ“ data/                     # Resultados e logs
â””â”€â”€ ğŸ“ config/                   # ConfiguraÃ§Ãµes
```

## ğŸ”§ TECNOLOGIAS UTILIZADAS

- **Python 3.10+** - Linguagem principal
- **Scrapy 2.13.3** - Framework de web scraping
- **Celery 5.x** - Sistema de filas assÃ­ncronas
- **Redis** - Broker de mensagens e cache
- **Requests** - Cliente HTTP
- **Pytest** - Framework de testes automatizados
- **Python-dotenv** - Gerenciamento de variÃ¡veis de ambiente

## ğŸ“ˆ STATUS DO PROJETO

- âœ… **NÃ­vel 1**: Scrapy bÃ¡sico funcional
- âœ… **NÃ­vel 2**: Sistema de filas implementado
- âœ… **NÃ­vel 3**: IntegraÃ§Ã£o CotefFÃ¡cil completa
- âœ… **Testes**: 58 testes automatizados passando
- âœ… **DocumentaÃ§Ã£o**: Completa e atualizada

## ğŸ“„ LICENÃ‡A

Este projeto foi desenvolvido para o Desafio CotefFÃ¡cil e estÃ¡ disponÃ­vel para fins educacionais e de avaliaÃ§Ã£o.

---

**ğŸ“ Desenvolvido para o Desafio CotefFÃ¡cil | Python + Scrapy + Celery + Redis**
```


---

## ğŸ›ï¸ ARQUITETURA DO SISTEMA

### ğŸ“Š Estrutura de DiretÃ³rios
```
PROVA/
â”œâ”€â”€ ğŸ“„ main.py                      # Arquivo principal - ponto de entrada
â”œâ”€â”€ ğŸ“„ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ ğŸ“„ .env                         # VariÃ¡veis de ambiente (configurar)
â”œâ”€â”€ ğŸ“„ pyproject.toml               # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ“„ scrapy.cfg                   # ConfiguraÃ§Ã£o do Scrapy
â”œâ”€â”€ ğŸ“„ run_tests.py                 # Script para executar testes
â”œâ”€â”€ ğŸ“„ README.md                    # Esta documentaÃ§Ã£o
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“ src/                        # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ“„ scrapy_wrapper.py       # Wrapper principal do Scrapy
â”‚   â”œâ”€â”€ ğŸ“„ pedido_queue_client.py  # Cliente para pedidos (NÃ­vel 3)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ config/                 # ConfiguraÃ§Ãµes do sistema
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ settings.py         # ConfiguraÃ§Ãµes internas
â”‚   â”‚   â””â”€â”€ ğŸ“„ paths.py            # Caminhos do projeto
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ nivel2/                 # Sistema de filas (NÃ­vel 2)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ queue_client.py     # Cliente de filas
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ tasks.py            # Tarefas Celery
â”‚   â”‚   â””â”€â”€ ğŸ“„ celery_app.py       # ConfiguraÃ§Ã£o Celery
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ nivel3/                 # Sistema de pedidos (Desafio)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ tasks.py            # Processamento completo de pedidos
â”‚   â”‚   â””â”€â”€ ğŸ“„ pedido_client.py    # Cliente do portal Servimed
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api_client/             # IntegraÃ§Ã£o CotefFÃ¡cil
â”‚   â”‚   â””â”€â”€ ğŸ“„ callback_client.py  # Cliente da API do desafio
â”‚   â”‚
â”‚   â”œâ”€â”€ ï¿½ scrapy_servimed/        # Projeto Scrapy
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ settings.py         # ConfiguraÃ§Ãµes Scrapy
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ pipelines.py        # Pipelines de processamento
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ items.py            # DefiniÃ§Ã£o de items
â”‚   â”‚   â””â”€â”€ ğŸ“ spiders/            # Spiders de scraping
â”‚   â”‚       â””â”€â”€ ğŸ“„ servimed_spider.py  # Spider principal
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ servimed_scraper/       # Sistema de processamento original
â”‚       â””â”€â”€ ğŸ“„ scraper.py          # Scraper completo standalone
â”‚
â”œâ”€â”€ ğŸ“ tests/                      # Testes automatizados
â”‚   â”œâ”€â”€ ğŸ“„ conftest.py             # ConfiguraÃ§Ãµes globais de teste
â”‚   â”œâ”€â”€ ğŸ“„ test_basic_functionality.py  # Testes bÃ¡sicos âœ…
â”‚   â”œâ”€â”€ ğŸ“„ test_config.py          # Testes de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“„ test_main.py            # Testes do main.py
â”‚   â””â”€â”€ ğŸ“„ test_scrapy_wrapper.py  # Testes do wrapper
â”‚
â”œâ”€â”€ ï¿½ data/                       # Dados e resultados
â”‚   â”œâ”€â”€ ï¿½ servimed_produtos_scrapy.json   # Resultados Scrapy
â”‚   â””â”€â”€ ğŸ“„ servimed_produtos_filtrados.json # Resultados filtrados
â”‚
â”œâ”€â”€ ğŸ“ config/                     # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ ï¿½ scripts/                    # Scripts auxiliares (Redis, Workers)
â””â”€â”€ ï¿½ tools/                      # Ferramentas (Redis portable)
```

---

## ğŸš€ INÃCIO RÃPIDO

### ğŸ“‹ PrÃ©-requisitos
- âœ… Python 3.10+
- âœ… ConexÃ£o com Internet
- âœ… Redis (para nÃ­veis 2 e 3)

### ğŸ”§ Setup RÃ¡pido

#### 1. Instalar dependÃªncias:
```bash
pip install -r requirements.txt
```

#### 2. Configurar ambiente (.env):
```bash
# Copiar .env.example para .env e configurar tokens
# Ver seÃ§Ã£o "ConfiguraÃ§Ã£o do Ambiente" para detalhes
```

#### 3. Testar funcionamento bÃ¡sico:
```bash
# NÃ­vel 1 - Scraping simples
python main.py --nivel 1 --filtro "paracetamol" --max-pages 1
```

### ğŸ“ Exemplos PrÃ¡ticos

#### ğŸ¯ Exemplo 1: Scraping de Produtos
```bash
# Buscar produtos com "dipirona" limitado a 2 pÃ¡ginas
python main.py --nivel 1 --filtro "dipirona" --max-pages 2

# Resultado: data/servimed_produtos_scrapy.json
```

#### ğŸ¯ Exemplo 2: Sistema de Pedidos (Desafio CotefFÃ¡cil)
```bash
# Criar pedido para produto especÃ­fico
python main.py --nivel 3 --codigo-produto 444212

# O sistema irÃ¡:
# 1. Buscar produto no Servimed
# 2. Criar pedido no portal
# 3. Gerar pedido aleatÃ³rio na API CotefFÃ¡cil
# 4. Enviar PATCH de confirmaÃ§Ã£o
```

#### ğŸ¯ Exemplo 3: Executar Testes
```bash
# Testes bÃ¡sicos
python -m pytest tests/test_basic_functionality.py -v

# Todos os testes
python run_tests.py
```

---

## ğŸ¯ NÃVEIS DE EXECUÃ‡ÃƒO

### ğŸ¯ NÃVEL 1: SCRAPING DE PRODUTOS (SÃNCRONO)
**DescriÃ§Ã£o:** ExtraÃ§Ã£o de dados de produtos do Servimed usando Scrapy

#### ğŸ”§ Como Usar:
```bash
# ExecuÃ§Ã£o bÃ¡sica (todos os produtos)
python main.py --nivel 1

# Com filtro de produtos
python main.py --nivel 1 --filtro "paracetamol"

# Limitando pÃ¡ginas para teste
python main.py --nivel 1 --max-pages 3

# Combinando opÃ§Ãµes
python main.py --nivel 1 --filtro "antibiotico" --max-pages 2
```

#### ğŸ“Š SaÃ­da:
- **Arquivo:** `data/servimed_produtos_scrapy.json`
- **Formato:** JSON com lista de produtos
- **Logs:** Console em tempo real
- **Estrutura:** `{produtos: [{gtin, codigo, descricao, preco_fabrica, estoque}]}`

---

### ğŸ¯ NÃVEL 2: SISTEMA DE FILAS (ASSÃNCRONO)
**DescriÃ§Ã£o:** Processamento via filas usando Celery + Redis  
**Uso:** Para processamento em larga escala e mÃºltiplas tarefas

#### ğŸ”§ PrÃ©-requisitos:
```bash
# 1. Iniciar Redis
# Windows: usar tools/redis-portable/redis-server.exe
# Ou Docker: docker run -d -p 6379:6379 redis:latest

# 2. Iniciar worker Celery
python -m celery -A src.nivel2.celery_app worker --loglevel=info
```

#### ğŸ”§ Como Usar:
```bash
# Verificar status dos workers
python main.py --nivel 2 --worker-status

# Enfileirar nova tarefa de scraping
python main.py --nivel 2 --enqueue --filtro "vitamina"

# Verificar status de tarefa especÃ­fica
python main.py --nivel 2 --status "task-id-aqui"
```

#### ğŸ“Š SaÃ­da:
- **Task ID** para acompanhamento
- **Status** da execuÃ§Ã£o via API
- **Resultados** armazenados no Redis

---

### ğŸ¯ NÃVEL 3: SISTEMA DE PEDIDOS (DESAFIO COTEFÃCIL)
**DescriÃ§Ã£o:** Sistema completo de processamento de pedidos conforme especificaÃ§Ã£o do desafio

#### ğŸ”§ Funcionalidades Implementadas:
1. âœ… **Busca de produtos** no Servimed via Scrapy
2. âœ… **CriaÃ§Ã£o de pedidos** no portal Servimed
3. âœ… **GeraÃ§Ã£o de pedido aleatÃ³rio** na API CotefFÃ¡cil
4. âœ… **PATCH de confirmaÃ§Ã£o** com cÃ³digo do pedido
5. âœ… **CÃ³digos Ãºnicos de rastreamento** baseados em caracterÃ­sticas do pedido

#### ğŸ”§ Como Usar:
```bash
# Criar pedido para produto especÃ­fico
python main.py --nivel 3 --codigo-produto 444212

# Modo de teste (sem criar pedido real)
python main.py --nivel 3 --test

# Verificar status de pedido
python main.py --nivel 3 --status "task-id"
```

#### ğŸ“Š Fluxo Completo do NÃ­vel 3:
```
1. Buscar produto 444212 no Servimed (via Scrapy)
2. Autenticar no portal Servimed 
3. Criar pedido no portal â†’ Recebe: {'executado': 'Ok'}
4. Gerar cÃ³digo Ãºnico: SERVIMED_13082025_1245_444212_01_7511
5. Chamar API CotefFÃ¡cil POST /pedido â†’ Recebe: {"id": 47}
6. Enviar PATCH /pedido/47 com {"codigo_fornecedor": "SERVIMED_..."}
7. ConfirmaÃ§Ã£o final no CotefFÃ¡cil
```

#### ğŸ·ï¸ **Formato do CÃ³digo de Pedido:**
```
SERVIMED_DDMMAAAA_HHMM_PRODUTO1_QTD_CLIENTE
Exemplo: SERVIMED_13082025_1245_444212_01_7511

Onde:
- SERVIMED: Identificador do sistema
- 13082025: Data (13/08/2025)
- 1245: HorÃ¡rio (12:45)
- 444212: CÃ³digo do primeiro produto
- 01: Quantidade total de itens
- 7511: Ãšltimos 4 dÃ­gitos do cliente
```

---

## âš™ï¸ CONFIGURAÃ‡ÃƒO DO AMBIENTE

### ğŸ“‹ DependÃªncias Principais
```txt
# === CORE (obrigatÃ³rias) ===
scrapy>=2.11.0              # Framework de scraping principal
requests>=2.31.0             # HTTP requests
python-dotenv>=1.0.0         # VariÃ¡veis de ambiente

# === NÃVEL 2 e 3 (Sistema de Filas e Pedidos) ===
celery>=5.3.0                # Framework de filas distribuÃ­das
redis>=5.0.0                 # Broker de mensagens

# === DESENVOLVIMENTO ===
pytest>=7.4.0                # Framework de testes
```

### ğŸ”§ InstalaÃ§Ã£o
```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Configurar Redis (para nÃ­veis 2 e 3)
# Windows: usar tools/redis-portable/redis-server.exe
# Ou Docker: docker run -d -p 6379:6379 redis:latest

# 3. Configurar .env (copiar de .env.example)
```

### ğŸ” VariÃ¡veis de Ambiente (.env)
```env
# === AUTENTICAÃ‡ÃƒO SERVIMED (obrigatÃ³rio) ===
ACCESS_TOKEN=seu_access_token_aqui
SESSION_TOKEN=seu_session_token_jwt_aqui
LOGGED_USER=codigo_usuario
CLIENT_ID=codigo_cliente
X_CART=hash_carrinho_usuario

# === CREDENCIAIS PORTAL (obrigatÃ³rio) ===
PORTAL_EMAIL=seu_email@dominio.com.br
PORTAL_PASSWORD=sua_senha_portal

# === API COTEFÃCIL - Desafio (obrigatÃ³rio para nÃ­vel 3) ===
CALLBACK_API_USER=seu_usuario_cotefacil@dominio.com.br
CALLBACK_API_PASSWORD=sua_senha_cotefacil
CALLBACK_URL=https://desafio.cotefacil.net

# === URLS DO SISTEMA (configuraÃ§Ã£o padrÃ£o) ===
PORTAL_URL=https://pedidoeletronico.servimed.com.br
BASE_URL=https://peapi.servimed.com.br

# === Redis/Celery (opcional - para nÃ­veis 2 e 3) ===
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
```

### ğŸ”‘ Como Obter os Tokens
1. **Abrir DevTools** no navegador (F12)
2. **Fazer login** no portal Servimed
3. **Na aba Network**, procurar requests para `/api/`
4. **Copiar headers**: `accesstoken`, `sessiontoken`, `loggeduser`, etc.
5. **Adicionar no .env**

---

## ğŸ§ª SISTEMA DE TESTES

###  Executando Testes

#### ğŸ¯ MÃ©todo 1: Script Automatizado
```bash
# Executar script interativo
python run_tests.py
```

#### ğŸ¯ MÃ©todo 2: Pytest Direto
```bash
# Todos os testes
python -m pytest tests/ -v

# Testes especÃ­ficos
python -m pytest tests/test_basic_functionality.py -v
python -m pytest tests/test_config.py -v

# Com cobertura de cÃ³digo
python -m pytest tests/ --cov=src --cov=main
```

### ğŸ“‹ Tipos de Testes Implementados

#### ğŸ”§ **Testes BÃ¡sicos** âœ…
- âœ… Ambiente Python funcional
- âœ… Estrutura do projeto
- âœ… ImportaÃ§Ãµes de mÃ³dulos
- âœ… DependÃªncias instaladas

#### ğŸ”— **Testes de ConfiguraÃ§Ã£o** âœ…
- âœ… Paths do projeto
- âœ… Arquivos de configuraÃ§Ã£o
- âœ… IntegraÃ§Ã£o de configuraÃ§Ãµes

---

## ğŸ› ï¸ COMANDOS ESSENCIAIS

### ï¿½ Para Uso DiÃ¡rio
```bash
# Scraping bÃ¡sico
python main.py --nivel 1 --filtro "produto" --max-pages 1

# Sistema de pedidos (Desafio CotefFÃ¡cil)
python main.py --nivel 3 --codigo-produto 444212

# Testes bÃ¡sicos
python -m pytest tests/test_basic_functionality.py -v
```

### ğŸ”§ Para Desenvolvimento
```bash
# Iniciar worker Celery (nÃ­veis 2 e 3)
python -m celery -A src.nivel2.celery_app worker --loglevel=info

# Verificar status do Redis
redis-cli ping

# Debug de imports
python -c "import sys; sys.path.insert(0, 'src'); import scrapy_wrapper; print('OK')"
```

### ï¿½ Para Troubleshooting
```bash
# Verificar estrutura
python -c "import os; print(os.listdir('.'))"

# Testar Scrapy
python -c "import scrapy; print(f'Scrapy {scrapy.__version__} OK')"

# Verificar dependÃªncias
pip list | grep -E "(scrapy|celery|redis|requests)"
```

---

## ğŸš¨ TROUBLESHOOTING

### âŒ Problemas Comuns

#### 1. **Redis nÃ£o estÃ¡ rodando** (NÃ­veis 2 e 3)
```bash
# Erro: ConnectionError: Error 10061 connecting to localhost:6379
# SoluÃ§Ã£o: Iniciar Redis
# Windows: tools/redis-portable/redis-server.exe
# Docker: docker run -d -p 6379:6379 redis:latest
```

#### 2. **Tokens expirados** (NÃ­vel 3)
```bash
# Erro: Token valido ate: [data passada]
# SoluÃ§Ã£o: Atualizar tokens no .env (extrair do navegador)
```

#### 3. **Workers Celery nÃ£o ativos** (NÃ­veis 2 e 3)
```bash
# Erro: No workers available
# SoluÃ§Ã£o: Iniciar worker
python -m celery -A src.nivel2.celery_app worker --loglevel=info
```

#### 4. **DependÃªncias faltando**
```bash
# Erro: ModuleNotFoundError
# SoluÃ§Ã£o: Instalar dependÃªncias
pip install -r requirements.txt
```

---

## ğŸ“ˆ RECURSOS DO SISTEMA

### ğŸ¯ **NÃ­vel 1: Scraping**
- Framework Scrapy para extraÃ§Ã£o robusta
- Filtros de busca personalizÃ¡veis
- Controle de paginaÃ§Ã£o
- Resultados em JSON estruturado

### ğŸ¯ **NÃ­vel 2: Filas AssÃ­ncronas**
- Processamento via Celery + Redis
- MÃºltiplas tarefas simultÃ¢neas
- Monitoramento de status
- Escalabilidade horizontal

### ğŸ¯ **NÃ­vel 3: Sistema de Pedidos (Desafio CotefFÃ¡cil)**
- âœ… IntegraÃ§Ã£o completa com portal Servimed
- âœ… CriaÃ§Ã£o real de pedidos
- âœ… CÃ³digos Ãºnicos de rastreamento
- âœ… IntegraÃ§Ã£o com API CotefFÃ¡cil
- âœ… PATCH automÃ¡tico de confirmaÃ§Ã£o
- âœ… Workflow completo do desafio

### ğŸ·ï¸ **Sistema de CÃ³digos Ãšnicos**
```
Formato: SERVIMED_DDMMAAAA_HHMM_PRODUTO_QTD_CLIENTE
Exemplo: SERVIMED_13082025_1245_444212_01_7511

BenefÃ­cios:
- ğŸ‘ï¸ LegÃ­vel por humanos
- ğŸ” RastreÃ¡vel por caracterÃ­sticas
- ğŸ”’ Ãšnico por timestamp + dados
- ğŸ“Š FÃ¡cil auditoria e debug
```

---

## âœ… RESUMO DO PROJETO

### ğŸ¯ **Funcionalidades Implementadas:**
- [x] **Scraping de produtos** via Scrapy (NÃ­vel 1)
- [x] **Sistema de filas** com Celery (NÃ­vel 2)
- [x] **Processamento de pedidos** completo (NÃ­vel 3)
- [x] **IntegraÃ§Ã£o CotefFÃ¡cil** 100% funcional
- [x] **CÃ³digos Ãºnicos** de rastreamento
- [x] **Testes automatizados** bÃ¡sicos

### ğŸ† **Desafio CotefFÃ¡cil: Status COMPLETO**
1. âœ… Busca de produtos no Servimed
2. âœ… CriaÃ§Ã£o de pedidos via portal
3. âœ… GeraÃ§Ã£o de pedido aleatÃ³rio na API
4. âœ… PATCH de confirmaÃ§Ã£o automÃ¡tico
5. âœ… CÃ³digos de rastreamento Ãºnicos

### ğŸ”§ **Tecnologias Utilizadas:**
- **Python 3.10+**
- **Scrapy 2.13.3** (Web Scraping)
- **Celery 5.x** (Filas AssÃ­ncronas)
- **Redis** (Broker de Mensagens)
- **Requests** (HTTP Client)
- **Pytest** (Testes Automatizados)

---

## ğŸ“ SUPORTE RÃPIDO

### âœ… **Para comeÃ§ar rapidamente:**
```bash
# 1. Teste bÃ¡sico
python main.py --nivel 1 --max-pages 1

# 2. Se funcionou, teste com filtro
python main.py --nivel 1 --filtro "vitamina" --max-pages 1

# 3. Para o desafio CotefFÃ¡cil
python main.py --nivel 3 --codigo-produto 444212
```

### ğŸš¨ **Se algo nÃ£o funcionar:**
```bash
# 1. Verificar ambiente
python -m pytest tests/test_basic_functionality.py -v

# 2. Verificar dependÃªncias
pip install -r requirements.txt

# 3. Para nÃ­vel 3, verificar .env e Redis
```

